{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlQvcmWWNd4Y"
   },
   "source": [
    "# Gradient of a Single-Point Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JtUZ9KYNd4Z"
   },
   "source": [
    "In this notebook, we calculate the gradient of quadratic cost with respect to a straight-line regression model's parameters. We keep the partial derivatives as simple as possible by limiting the model to handling a single data point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EdScrjQCNd4Z"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Oem10L3iNd4d"
   },
   "outputs": [],
   "source": [
    "xs = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jPZsXuwWNd4f"
   },
   "outputs": [],
   "source": [
    "ys = torch.tensor([1.86, 1.31, .62, .33, .09, -.67, -1.23, -1.37])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yM6hk9NeNd4i"
   },
   "source": [
    "The slope of a line is given by $y = mx + b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NtyilFoYNd4i"
   },
   "outputs": [],
   "source": [
    "def regression(my_x, my_m, my_b):\n",
    "    return my_m*my_x + my_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROV3p3BHNd4l"
   },
   "source": [
    "Let's initialize $m$ and $b$ with the same \"random\" near-zero values as we did in the *Regression in PyTorch* notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qmiBbvH1Nd4l"
   },
   "outputs": [],
   "source": [
    "m = torch.tensor([0.9]).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TRxe0rU9Nd4n"
   },
   "outputs": [],
   "source": [
    "b = torch.tensor([0.1]).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Iu4uKsqNd4r"
   },
   "source": [
    "To keep the partial derivatives as simple as possible, let's move forward with a single instance $i$ from the eight possible data points: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_ttss5lTNd4s"
   },
   "outputs": [],
   "source": [
    "i = 7\n",
    "x = xs[i]\n",
    "y = ys[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TO7ozmjeNd4u",
    "outputId": "5e072736-5c54-4456-952a-471e5239fda5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b63IzdS1Nd4x",
    "outputId": "892dc353-4ba2-4886-fe6e-18aa59bbd51a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.3700)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVkbo0oPNd4z"
   },
   "source": [
    "**Step 1**: Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_bUxX__Nd4z"
   },
   "source": [
    "We can flow the scalar tensor $x$ through our regression model to produce $\\hat{y}$, an estimate of $y$. Prior to any model training, this is an arbitrary estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBB2iwPiNd40",
    "outputId": "7e9530ce-f15b-4998-d776-29f09140aa6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.4000], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = regression(x, m, b)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Hy2sDlNNd42"
   },
   "source": [
    "**Step 2**: Compare $\\hat{y}$ with true $y$ to calculate cost $C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtHOeylJNd43"
   },
   "source": [
    "In the *Regression in PyTorch* notebook, we used mean-squared error, which averages quadratic cost over multiple data points. With a single data point, here we can use quadratic cost alone. It is defined by: $$ C = (\\hat{y} - y)^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "t-THZMH0Nd43"
   },
   "outputs": [],
   "source": [
    "def squared_error(my_yhat, my_y):\n",
    "    return (my_yhat - my_y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LSKXx5XNd45",
    "outputId": "08d223f2-c5e1-4f7c-d5f4-750ab79dc002"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([60.3729], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = squared_error(yhat, y)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wu4nlO3-Nd47"
   },
   "source": [
    "**Step 3**: Use autodiff to calculate gradient of $C$ w.r.t. parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Mk9Lx-gTNd48"
   },
   "outputs": [],
   "source": [
    "C.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXQJxYduNd4-"
   },
   "source": [
    "The partial derivative of $C$ with respect to $m$ ($\\frac{\\partial C}{\\partial m}$) is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1yQ7w1bfNd4-",
    "outputId": "d0c4d659-729b-4e97-b622-7f02b7445f46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([108.7800])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGK1NwomNd5B"
   },
   "source": [
    "And the partial derivative of $C$ with respect to $b$ ($\\frac{\\partial C}{\\partial b}$) is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIeBu-tINd5B",
    "outputId": "ac2461e7-90ec-430e-93cd-51cf67e792f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15.5400])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NK1tyH4WNd5E"
   },
   "source": [
    "**Return to *Calculus II* slides here to derive $\\frac{\\partial C}{\\partial m}$ and $\\frac{\\partial C}{\\partial b}$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTgfR-wINd5F"
   },
   "source": [
    "$$ \\frac{\\partial C}{\\partial m} = 2x(\\hat{y} - y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKjWDa4QNd5F",
    "outputId": "5d29bb67-6538-4ff9-a868-85927f114c21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(108.7800)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*x*(yhat.item()-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCV3zMIjNd5H"
   },
   "source": [
    "$$ \\frac{\\partial C}{\\partial b} = 2(\\hat{y}-y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNrOSpcONd5H",
    "outputId": "73b37a87-7535-4049-9587-aa8b1831c69f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.5400)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*(yhat.item()-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXor7Ev7Nd5J"
   },
   "source": [
    "### The Gradient of Cost, $\\nabla C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeII8EHQNd5K"
   },
   "source": [
    "The gradient of cost, which is symbolized $\\nabla C$ (pronounced \"nabla C\"), is a vector of all the partial derivatives of $C$ with respect to each of the individual model parameters: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVnD7j3HNd5K"
   },
   "source": [
    "$\\nabla C = \\nabla_p C = \\left[ \\frac{\\partial{C}}{\\partial{p_1}}, \\frac{\\partial{C}}{\\partial{p_2}}, \\cdots, \\frac{\\partial{C}}{\\partial{p_n}} \\right]^T $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILK7BRLJNd5K"
   },
   "source": [
    "In this case, there are only two parameters, $b$ and $m$: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Yq3BQ3YNd5L"
   },
   "source": [
    "$\\nabla C = \\left[ \\frac{\\partial{C}}{\\partial{b}}, \\frac{\\partial{C}}{\\partial{m}} \\right]^T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZsZhOKFZNd5L",
    "outputId": "d3dc7def-3e43-40c2-9eb2-d7b86db95994"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 15.5400],\n",
       "        [108.7800]])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient = torch.tensor([[b.grad.item(), m.grad.item()]]).T\n",
    "gradient"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "single-point-regression-gradient.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
